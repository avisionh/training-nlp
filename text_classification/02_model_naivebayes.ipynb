{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# pass in previously stored df\n",
    "%store -r df_bbc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test set splitting\n",
    "Are now splitting our dataset into the train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set input and output matrices\n",
    "X = df_bbc['article_text_clean']\n",
    "y = df_bbc['category']\n",
    "\n",
    "# set train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** As we saw our categories are relatively well-balanced, we would expect the balanced categories to also apply when we randomly split our dataset into the train and test set. In this way, we expect the train and test set categories to be similarly distributed.\n",
    "\n",
    "We may revisit this assumption if we have overfitting.\n",
    "\n",
    "***\n",
    "## Model: Naive Bayes\n",
    "Having loaded and preprocessed our labelled data, we can start including some feature engineering.\n",
    "\n",
    "We will convert our text documents to a matrix of token counts using `CountVectorizer`, then transform this count matrix to a normalised *tf-idf* representation (via the tf-idf transformer). Then will train several classifiers from the scikit-learn library.\n",
    "\n",
    "#### TF-IDF\n",
    "*Term frequency-inverse document frequency* is a statistical measure that evaulates how relevant a word is to a document in a collection of documents. This is computed by multiplying two metrics:\n",
    "- (TF) Term frequency, which is the number of times a word appears in a document\n",
    "- (IDF) Inverse document frequency of the word across a set of documents\n",
    "\n",
    "Words that are common in every document, such as *'this'*, *'the'*, *'what'* are ranked low, even thought they appear many times. This is because they don't mean much to that document in particular. Whereas if words such as *'football'* appear many times in a document, whilst not appearing many times in others, it probabily means it's very relevant, hence the word *'football'* will probably be tied to the category/topic, *'Sport'* since most documents/articles containing the word *'football'* will be about this category/topic.\n",
    "\n",
    "*[Reference: [MonkeyLearn blog, 2019](https://monkeylearn.com/blog/what-is-tf-idf/)]*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
       "                ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_naivebayes = Pipeline(steps = [('vect', CountVectorizer()),\n",
    "                                     ('tfidf', TfidfTransformer()),\n",
    "                                     ('clf', MultinomialNB())])\n",
    "model_naivebayes.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.970\n",
      "CPU times: user 141 ms, sys: 4.58 ms, total: 146 ms\n",
      "Wall time: 146 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = model_naivebayes.predict(X_test)\n",
    "\n",
    "print('Accuracy: {:.3f}'.format(accuracy_score(y_pred, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "entertainment       0.95      0.99      0.97       144\n",
      "     business       0.99      0.91      0.95       110\n",
      "        sport       0.95      0.98      0.96       129\n",
      "     politics       0.98      1.00      0.99       164\n",
      "         tech       0.98      0.96      0.97       121\n",
      "\n",
      "     accuracy                           0.97       668\n",
      "    macro avg       0.97      0.97      0.97       668\n",
      " weighted avg       0.97      0.97      0.97       668\n",
      "\n"
     ]
    }
   ],
   "source": [
    "list_categories = df_bbc['category'].unique()\n",
    "print(classification_report(y_test, y_pred, target_names = list_categories))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From looking at the accuracy, it's actually really good, 97%! Wow, can we do better than this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'object_keep' (dict)\n"
     ]
    }
   ],
   "source": [
    "object_keep = {'df_bbc': df_bbc,\n",
    "               'X': X,\n",
    "               'y': y,\n",
    "               'X_train': X_train,\n",
    "               'X_test': X_test,\n",
    "               'y_train': y_train,\n",
    "               'y_test': y_test}\n",
    "%store object_keep"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_nlp",
   "language": "python",
   "name": "env_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
