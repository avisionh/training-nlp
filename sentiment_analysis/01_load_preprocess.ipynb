{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semi-Supervised Learning\n",
    "Code taken from [Analytics Vidhya](https://www.analyticsvidhya.com/blog/2017/09/pseudo-labelling-semi-supervised-learning-technique/) and data is from their data hack challenge, further details available [here](https://datahack.analyticsvidhya.com/contest/practice-problem-big-mart-sales-iii/#ProblemStatement).\n",
    "\n",
    "The problem statement being tackled in this dataset and exercise is:\n",
    "\n",
    "> Predicting sales for Big Mart outlets\n",
    "\n",
    "## Background\n",
    "The data scientists at BigMart have collected 2013 sales data for 1559 products across 10 stores in different cities. Also, certain attributes of each product and store have been defined. The aim is to build a predictive model and predict the sales of each product at a particular outlet.\n",
    "\n",
    "Using this model, BigMart will try to understand the properties of products and outlets which play a key role in increasing sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import BayesianRidge, Ridge, ElasticNet\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "\n",
    "# display multiple outputs in same cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PseudoLabeler(BaseEstimator, RegressorMixin):\n",
    "    '''\n",
    "    Sci-kit learn wrapper for creating pseudo-lebeled estimators.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, model, unlabled_data, features, target, sample_rate=0.2, seed=42):\n",
    "        '''\n",
    "        @sample_rate - percent of samples used as pseudo-labelled data\n",
    "        from the unlabelled dataset\n",
    "        '''\n",
    "        assert sample_rate <= 1.0, 'Sample_rate should be between 0.0 and 1.0.'\n",
    "\n",
    "        self.sample_rate = sample_rate\n",
    "        self.seed = seed\n",
    "        self.model = model\n",
    "        self.model.seed = seed\n",
    "\n",
    "        self.unlabled_data = unlabled_data\n",
    "        self.features = features\n",
    "        self.target = target\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return {\n",
    "        \"sample_rate\": self.sample_rate,\n",
    "        \"seed\": self.seed,\n",
    "        \"model\": self.model,\n",
    "        \"unlabled_data\": self.unlabled_data,\n",
    "        \"features\": self.features,\n",
    "        \"target\": self.target\n",
    "        }\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        '''\n",
    "        Fit the data using pseudo labeling.\n",
    "        '''\n",
    "\n",
    "        augemented_train = self.__create_augmented_train(X, y)\n",
    "        self.model.fit(\n",
    "            augemented_train[self.features],\n",
    "            augemented_train[self.target]\n",
    "        )\n",
    "\n",
    "        return self\n",
    "\n",
    "    def __create_augmented_train(self, X, y):\n",
    "        '''\n",
    "        Create and return the augmented_train set that consists\n",
    "        of pseudo-labeled and labeled data.\n",
    "        '''\n",
    "        num_of_samples = int(len(self.unlabled_data) * self.sample_rate)\n",
    "\n",
    "        # Train the model and creat the pseudo-labels\n",
    "        self.model.fit(X, y)\n",
    "        pseudo_labels = self.model.predict(self.unlabled_data[self.features])\n",
    "\n",
    "        # Add the pseudo-labels to the test set\n",
    "        pseudo_data = self.unlabled_data.copy(deep = True)\n",
    "        pseudo_data[self.target] = pseudo_labels\n",
    "\n",
    "        # Take a subset of the test set with pseudo-labels and append in onto\n",
    "        # the training set\n",
    "        sampled_pseudo_data = pseudo_data.sample(n=num_of_samples)\n",
    "        temp_train = pd.concat([X, y], axis=1)\n",
    "        augemented_train = pd.concat([sampled_pseudo_data, temp_train])\n",
    "\n",
    "        return shuffle(augemented_train)\n",
    "\n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        Returns the predicted values.\n",
    "        '''\n",
    "        return self.model.predict(X)\n",
    "\n",
    "    def get_model_name(self):\n",
    "        return self.model.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(filepath_or_buffer = '../data/data_mart_train.csv')\n",
    "df_test = pd.read_csv(filepath_or_buffer = '../data/data_mart_test.csv')\n",
    "\n",
    "df_train['dataset_identifier'] = 'train'\n",
    "df_test['dataset_identifier'] = 'test'\n",
    "\n",
    "df_test['Item_Outlet_Sales'] = np.NaN\n",
    "\n",
    "# union/concatenate dataframes so can perform similar operations\n",
    "df = pd.concat([df_train, df_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowercase headings\n",
    "df.columns = df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_nlp",
   "language": "python",
   "name": "env_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
